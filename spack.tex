%-------------------------------------------------------------------------------
\section{Spack}
%-------------------------------------------------------------------------------
\label{sec:software-model}

\spack~\cite{gamblin+:sc15} is a package manager designed to support High Performance
Computing (HPC). Like functional package managers, \spack installs packages in separate
prefixes to allow arbitrarily many installations to coexist. This enables users to build
many different variants of a package, e.g., with different compilers, different MPI
implementations, different flags, or with combinations of all three of these parameters.
This greatly expands the space of possible build configurations.

At a high level, \spack can be broken down into three primary components. The {\it spec
  syntax} allows users to easily specify and constrain builds on the command line. The
{\it package domain-specific language (DSL)} expresses parameterized build recipes for
software packages, and the {\it concretizer} is Spack's dependency solver. The
concretizer combines {\it abstract} (i.e., underspecified) spec constraints from the
user and from packages, and it produces a {\it concrete}, or fully specified package
spec that can be installed. We provide an overview of these pieces here but full details
are in the original paper~\cite{gamblin+:sc15}.

\subsection{Spec Syntax}
\label{sec:specs}

Spack calls its internal dependency graphs ``specs'' because they specify parameters of
a software installation along with those of its dependencies. Specs are directed acyclic
graphs where nodes are packages and edges are dependency relationships. The ``spec
syntax'' is a shorthand for expressing constraints on these graphs. Each node of the
graph has parameters, including
\begin{enumerate*}
\item the package name;
\item the version to build;
\item variants (compile-time build options);
\item the compiler to build with and its version;
\item compiler flags;
\item the target operating system;
\item the target microarchitecture; and
\item the package installation's dependencies.
\end{enumerate*}

\input{sigil-tab}

The spec syntax in \spack allows users to specify preferences within this combinatorial
build space. In the simplest case, a user might want to build a particular package {\it
  without} any concern for its configuration. In this case they would write:
\begin{minted}[fontsize=\small,bgcolor=bg]{text}
spack install hdf5
\end{minted}
Spack will install {\tt hdf5} without any particular customization.
Table~\ref{tab:sigil} shows examples of {\it sigils} that can be used to specify
specific constraints on specs, including any of the attributes listed above. The spec
syntax is fully recursive, in that users can specify constraints on dependencies using
the {\tt \^{}} (``depends on'') sigil. For example, the spec below:
\begin{minted}[fontsize=\small,bgcolor=bg]{text}
hdf5@1.10.2 ^zlib%gcc ^cmake target=aarch64
\end{minted}
means ``any possible build of the package \texttt{hdf5} at version {\tt 1.10.2} that
depends on a build of the package \texttt{zlib} built with the \texttt{gcc} compiler and
a build of the package \texttt{cmake} built to target the \texttt{aarch64}
architecture''. While users could completely constrain a build via the spec syntax, in
practice they only care about a comparatively small set of constraints, and they rely on
concretization to select values for unspecified parameters. We refer to a portion of the
build space in \spack as an ``abstract spec'', and a fully specified build as a
``concrete spec''.

\subsection{Package DSL}
\label{sec:package-dsl}

\begin{figure}
\begin{minted}[linenos,numbersep=-5pt,fontsize=\footnotesize]{python}
  # This is the class name for the package `example`
  class Example(Package):
      """Example depends on zlib, mpi, and optionally bzip2"""

      version("1.1.0")
      version("1.0.0")

      variant("bzip", default=True, description="enable bzip")

      # Depends on bzip2 or later when bzip is enabled
      depends_on("bzip2@1.0.7:", when="+bzip")
      depends_on("zlib")  # depends on zlib
      # Newer versions require newer versions of zlib
      depends_on("zlib@1.2.8:", when="@1.1.0:")

      # Depends on *some* MPI implementation
      depends_on("mpi")

      # Known failure when building with intel compilers
      conflicts("%intel")
      # Does not support architectures derived from ARM64
      conflicts("target=aarch64:")

      def install(self, spec, prefix):
          # Translate spec into arguments to build system
          config_args = ['--with-zlib=%s' % spec['zlib'].prefix]

          if 'bzip2' in spec:
              bz_arg = '--with-bzip=%s' % spec['bzip2'].prefix
          else:
              bz_arg = '--without-bzip'
          config_args.append(bz_arg)

          # Run the build
          configure(*config_args)
          make()
          make('install')
\end{minted}
\caption{
  A {\tt package.py} file written in Spack's embedded DSL.
  \label{fig:example-spack-package}
  \vspace{-3em}
}
\end{figure}

Figure~\ref{fig:example-spack-package} shows Spack's package DSL. Unlike many systems, a
package in \spack is a {\it parameterized} Python class. There is {\it one} package
recipe for each package, and it is {\it instantiated} for each concrete spec that Spack
builds. The {\tt install()} function on line 24 takes a fully concrete spec as one of
its parameters, and its job is to install {\it that} particular configuration of the
{\tt example} package into the specified {\tt prefix}.

The install instructions on lines 24-37 do the work of the build, but more interesting
for this paper are the metadata directives on lines 5-22. This package has two possible
versions, {\tt 1.0.0} and {\tt 1.1.0}. It has one build option, or ``variant'', called
{\tt bzip} that enables the dependency on {\tt bzip2}. Its dependency on {\tt zlib} is
dependent on its version. Conditions like these are specified using {\tt when} clauses
within directives. It has some {\tt conflicts}---conditions under which it is known not to build
successfully. Dependency constraints, conflicts, and {\tt when} clauses are all
specified concisely using the  spec syntax.
%
The dependency on {\tt mpi} on line 17 is special. Spack provides support for packages
that are source-compatible (API-compatible), like MPI. There is no concrete {\tt mpi}
package in Spack, rather there are several {\tt mpi} {\it providers}, like {\tt mpich},
{\tt openmpi}, etc. This package can be instantiated with {\it any} of these MPI
providers. We thus call {\tt mpi} a``virtual dependency''. {\tt blas} and {\tt lapack}
are two other common examples in HPC.

\subsection{Concretization}

Spack can build the {\tt example} package in Figure~\ref{fig:example-spack-package} in
{\it many} different ways. The metadata in the package DSL exposes a combinatorial build
configuration space, and it is the {\it concretizer}'s job to select a configuration.
The {\it concretizer} is Spack's dependency solver, so called because it converts
partially constrained \emph{abstract specs} to fully constrained \emph{concrete specs}
that can be built when combined with installation methods in the package DSL.
%
There are three primary inputs to concretization in \spack: specs on the command line,
constraints from the package DSL, and additional preferences from user configuration
files. Without loss of generality, we consider only the first two here.
%; user
%configuration simply adds more preferences.
%
%The
%user configuration allows the user to change the default behaviors of \spack, but is not
%necessary to understand the workings of the concretizer. In the following discussion of
%the concretizer, in many places the algorithm will ``choose the default'' or ``choose
%the most preferred ...'' when otherwise unconstrained. In all of those cases, \spack has
%builtin defaults that can be overriden with user configuration.
%
%For each virtual
%dependency, even more options arise to complicate the build space as an implementation
%must be selected in addition to all of the decisions necessasary to build that
%implementation.
%
\subsubsection{Validity}

On a conceptual level, we can think of the concretizer as accomplishing two tasks.
First, it determines the set of packages needed in the spec DAG. Second, it fills in any
missing nodal parameters (enumerated in Section~\ref{sec:specs}). Every decision made by
the concretizer must consider constraints from all the input sources; any unsatisfied
constraints imply an {\it invalid} solution. We say a solution is {\it valid} if and only if:
\begin{itemize}
\item all virtuals are replaced with concrete dependencies;
\item all dependencies are resolved;
\item all node parameters have been assigned values; and
\item all input constraints are satisfied.
\end{itemize}

\subsubsection{Completeness}
The original Spack concretizer used a greedy, fixed-point algorithm. The issue with this
algorithm (and all greedy algorithms) is that it only made {\it local} decisions about
dependencies and node parameters, and it could not backtrack to undo decisions that it
made. A solver is {\it complete} if it finds a solution when one exists; this property
of the original concretizer made it {\it incomplete}.

Consider our package \texttt{example} from Section~\ref{sec:package-dsl}, we will
concretize the abstract spec:
\begin{minted}[fontsize=\small,bgcolor=bg]{text}
example@1.0.0 ^zlib@1.2.11
\end{minted}
We will assume for the moment that neither \texttt{zlib} nor \texttt{bzip2} have any
additional dependencies. Then the set of package constraints needed for this
abstract spec is

\begin{itemize}
\item {\tt example@1.0.0} from the abstract spec: example v1.0.0
\item {\tt bzip2@1.0.7:} from {\tt example}: bzip2 v1.0.7 or higher
\item {\tt zlib@1.2.11} from abstract spec: zlib version 1.2.11
\item {\tt mpi} from {\tt example} package: any MPI implementation
\end{itemize}

The original concretizer would simply proceed until all decisions had been made,
stopping at the first conflict it found with any prior decision. The
resulting concrete spec might be:
\begin{minted}[fontsize=\footnotesize,bgcolor=bg]{text}
example@1.0.0+bzip%gcc@11.2.0 arch=linux-centos8-skylake
  ^bzip2@1.0.8+pic%gcc@11.2.0 arch=linux-centos8-skylake
  ^zlib@1.2.11+pic%gcc@11.2.0 arch=linux-centos8-skylake
  ^mpich@3.1 pmi=pmix %gcc@11.2.0 arch=linux-centos8-skylake
\end{minted}
Here, all dependencies are expanded, all virtual packages have been replaced, all node
parameters (variants, compilers, targets, etc.) have been assigned and no constraints
are violated. Decisions regarding node attributes not specified in the abstract spec nor
in the package constraints were made from defaults. But, imagine that {\tt mpich} had a
conflict with {\tt bzip2@1.0.7}. In our example, we were lucky that the concretizer
selected {\tt bzip2@1.0.8} to satisfy the constraint {\tt bzip2@1.0.7:} (recall that
means \texttt{bzip2} at version 1.0.7 or higher). Had the default choice been {\tt
  bzip2@1.0.7}, there would have been no way for the algorithm to backtrack, and it would
report an error without finding the solution.

\subsubsection{Optimality}
There are usually many {\it valid} solutions to concretization problems, but users
prefer some solutions over others. For a fresh installation, users generally prefer the
newest version of a package. They prefer certain defaults for build options and
variants, and HPC users tend to prefer specific microarchitecture targets with vector
instructions, e.g., {\tt skylake} or {\tt cascadelake} with AVX-512 support vs. generic
{\tt x86\_64}. We say a solver is {\it optimal} when it can find the best valid solution
according to some set of formal criteria. Since the original concretizer was not
complete, it also could not be optimal, as it could never consider all possibilities.
Note that this definition of optimality does {\it not} refer to the performance of built
binaries, though it may be related depending on the criteria chosen. We discuss details
of specific optimization criteria in later sections.

In addition to these issues, the original concretizer was implemented directly on the
dependency graph structure in memory. Any new semantics had to be implemented with
complex graph algorithms, and graph nodes and edges had to be configured and updated
manually. This process was error-prone and limited the speed of development and the
complexity of the semantics that could be considered.
